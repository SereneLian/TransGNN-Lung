{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9668e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2163cda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import GraphConv, SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53a2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsurv_utils import c_index, adjust_learning_rate\n",
    "from loss import NegativeLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "782cd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "all_patient_info = pd.read_csv(\"/home/jielian/lung-graph-project/data/csv/SPH0812.csv\")\n",
    "stage1 = list(np.load(\"/home/jielian/lung-graph-project/data/seg_image/labels/name_stage1.npy\"))\n",
    "stage2 = list(np.load(\"/home/jielian/lung-graph-project/data/seg_image/labels/name_stage2.npy\"))\n",
    "patint_list = [*stage1, *stage2]\n",
    "patient_info = all_patient_info[all_patient_info['folder_name'].isin(patint_list)]\n",
    "feature_files = os.listdir(\"trans_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d65ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "name = []\n",
    "for feature_name in feature_files:\n",
    "    path = \"trans_feature/\"+feature_name\n",
    "    name.append(int(feature_name[:-4]))\n",
    "    feature = list(np.load(path, allow_pickle=True))\n",
    "    data.append(feature)\n",
    "feature_data = pd.DataFrame(data)\n",
    "feature_data['folder_name']=name\n",
    "all_data = patient_info.merge(feature_data, how='left', on='folder_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eae9c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training survival distribution:\n",
      "0    991\n",
      "1    287\n",
      "Name: OS_Status, dtype: int64\n",
      "validation survival distribution:\n",
      "0    173\n",
      "1     41\n",
      "Name: OS_Status, dtype: int64\n",
      "test survival distribution:\n",
      "0    169\n",
      "1     44\n",
      "Name: OS_Status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_id = np.load(\"data_ind/train_index.npy\",allow_pickle=True)\n",
    "val_id = np.load(\"data_ind/val_index.npy\", allow_pickle=True)\n",
    "test_id = np.load(\"data_ind/test_index.npy\",allow_pickle=True)\n",
    "idx_train = torch.LongTensor(train_id)\n",
    "idx_val = torch.LongTensor(val_id)\n",
    "idx_test = torch.LongTensor(test_id)\n",
    "\n",
    "print(\"training survival distribution:\")\n",
    "print(all_data.iloc[train_id,:]['OS_Status'].value_counts())\n",
    "print(\"validation survival distribution:\")\n",
    "print(all_data.iloc[val_id,:]['OS_Status'].value_counts())\n",
    "print(\"test survival distribution:\")\n",
    "print(all_data.iloc[test_id,:]['OS_Status'].value_counts())\n",
    "\n",
    "\n",
    "# print(\"training survival distribution:\")\n",
    "# print(all_data.iloc[train_id,:]['RFS_Status'].value_counts())\n",
    "# print(\"validation survival distribution:\")\n",
    "# print(all_data.iloc[val_id,:]['RFS_Status'].value_counts())\n",
    "# print(\"test survival distribution:\")\n",
    "# print(all_data.iloc[test_id,:]['RFS_Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec90816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.24984968029262525, 0.2920858035783425)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "data = all_data['RFS_Status'].to_list()\n",
    "print(st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a401f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = [*train_id, *val_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d9aec32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      488\n",
       "1      370\n",
       "5      247\n",
       "2      211\n",
       "4       99\n",
       "45      47\n",
       "12      14\n",
       "34      13\n",
       "345      2\n",
       "35       1\n",
       "Name: Location_1_LUL_2_LLL_3_RUL_4_RML_5_RLL, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.iloc[ttt,:]['Location_1_LUL_2_LLL_3_RUL_4_RML_5_RLL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df4b6d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16554959785522788"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "247/(384+211+504+146+247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e35452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define similarity of two patient\n",
    "def SimScore(a1,a2,s1,s2,l1,l2,h1,h2,t1,t2,n1,n2,m1,m2,tnm1,tnm2): \n",
    "    c_score = 0\n",
    "    h_score = 0\n",
    "    t_score = 0\n",
    "    # sex and age\n",
    "    if s1 == s2:\n",
    "        c_score +=1\n",
    "    if abs(a1-a2) <= 5:\n",
    "        c_score +=1\n",
    "    \n",
    "    if l1 == l2:\n",
    "        h_score +=1\n",
    "    if h1 == h2:\n",
    "        h_score +=1\n",
    "    \n",
    "    if t1 == t2:\n",
    "        t_score +=1\n",
    "    if n1 == n2:\n",
    "        t_score +=1\n",
    "    if m1 == m2:\n",
    "        t_score +=1\n",
    "#     if tnm1 == tnm2:\n",
    "#         t_score +=1\n",
    "\n",
    "    return c_score*t_score*h_score\n",
    "\n",
    "# def SimScore(a1,a2,s1,s2,l1,l2,h1,h2,t1,t2,n1,n2,m1,m2,tnm1,tnm2): \n",
    "\n",
    "#     return c_score*t_score*h_score\n",
    "\n",
    "\n",
    "def adj_matrix(patient_info):\n",
    "    age = patient_info['Age'].to_list()\n",
    "    sex = patient_info['Sex_1_male_2_female'].to_list()\n",
    "    \n",
    "    loc = patient_info['Location_1_LUL_2_LLL_3_RUL_4_RML_5_RLL'].to_list()\n",
    "    his = patient_info['Histology_1_Adenocarcinoma_2_SquamousCellCarcinoma_3_Others'].to_list()\n",
    "    pts = patient_info['pT_Stage'].to_list()\n",
    "    pns = patient_info['pN_Stage'].to_list()\n",
    "    pms = patient_info['pM_Stage'].to_list()\n",
    "    tnm = patient_info['pTNM'].to_list()\n",
    "\n",
    "    edge_list=[]\n",
    "    edge_wight=[]\n",
    "    n_sample = len(age)\n",
    "    adj = np.zeros((n_sample, n_sample))\n",
    "    for i in tqdm(range(n_sample)):\n",
    "        for j in range(n_sample):\n",
    "            adj[i,j] = SimScore(age[i],age[j],sex[i],sex[j],loc[i],loc[j],his[i],his[j],\n",
    "                                pts[i],pts[j],pns[i],pns[j], pms[i],pms[j],tnm[i],tnm[j])\n",
    "            if adj[i,j] != 0:\n",
    "                edge_list.append([i,j])\n",
    "                edge_wight.append(adj[i,j])\n",
    "    return adj, edge_list,edge_wight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e8866c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1705/1705 [00:04<00:00, 366.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of edges in this graph: 1342873\n",
      "Number of average degree:  787.608797653959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adj, edge_list, edge_wight = adj_matrix(all_data)\n",
    "print(\"the number of edges in this graph:\",len(edge_list))\n",
    "print(\"Number of average degree: \",len(edge_list)/1705 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97603d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jielian/anaconda3/envs/gnn/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# save the labels\n",
    "norm_label = all_data['OS_Month']\n",
    "# norm_label = (all_data['OS_Month']-np.min(all_data['OS_Month']))/(np.max(all_data['OS_Month'])-np.min(all_data['OS_Month']))\n",
    "labels = torch.from_numpy(norm_label.to_numpy())\n",
    "events = torch.from_numpy(all_data['OS_Status'].to_numpy())\n",
    "# build graph struture data\n",
    "g = dgl.DGLGraph()\n",
    "g.add_nodes(len(labels))\n",
    "# add nodes\n",
    "# node_feature = (all_data.iloc[:, 15:]-all_data.iloc[:, 15:].min())/(all_data.iloc[:, 15:].max()- all_data.iloc[:, 15:].min())\n",
    "node_feature = all_data.iloc[:, 15:]\n",
    "# print(node_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c77c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_norm = node_feature.to_numpy()\n",
    "g.ndata['h'] = torch.from_numpy(node_feature_norm).float()\n",
    "g.ndata['event'] = events\n",
    "g.ndata['label'] = labels\n",
    "g.ndata\n",
    "# g.adj = adj\n",
    "# add edges\n",
    "src, dst = tuple(zip(*edge_list))\n",
    "g.add_edges(src, dst)\n",
    "# add edge weight\n",
    "edge_wight = np.array(edge_wight)\n",
    "g.edata['w'] = torch.from_numpy(edge_wight).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637ca099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, dropout=0, activation = None,aggregator_type='mean'):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_feats, hid_feats) \n",
    "        self.conv1 = SAGEConv(in_feats=hid_feats, out_feats=64, aggregator_type=aggregator_type, activation=activation, feat_drop=dropout)\n",
    "        self.conv2 = SAGEConv(in_feats=64, out_feats= out_feats, aggregator_type=aggregator_type, activation=activation, feat_drop=dropout)\n",
    "        self.fc2 = nn.Linear(out_feats, 1) \n",
    "    def forward(self, graph, inputs, w_input):\n",
    "        # inputs are features of nodes\n",
    "#         graph.ndata['h']= self.fc1(inputs)\n",
    "        h = self.fc1(inputs)\n",
    "        if w_input != None:\n",
    "            h = self.conv1(graph, h, w_input)\n",
    "        else:\n",
    "            h = self.conv1(graph, h)\n",
    "        h = self.conv2(graph,h)\n",
    "#         print(h.size())\n",
    "#         output=F.relu(self.fc2(h))\n",
    "        output=self.fc2(h)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b777c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, activation = F.softmax, norm =\"both\"):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_feats, hid_feats) \n",
    "        self.conv1 = GraphConv(in_feats=hid_feats, out_feats= hid_feats, activation=activation, norm=norm)\n",
    "        self.conv2 = GraphConv(in_feats=hid_feats, out_feats= out_feats,  activation=activation, norm=norm)\n",
    "        self.fc2 = nn.Linear(out_feats, 1) \n",
    "        \n",
    "    def forward(self, graph, inputs, w_input):\n",
    "        # inputs are features of nodes\n",
    "        h= self.fc1(inputs)\n",
    "        h = self.conv1(graph, h)\n",
    "        h = self.conv2(graph,h)\n",
    "#         output=F.relu(self.fc2(h))\n",
    "        h=self.fc2(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b814b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, model, save_dic, idx_train,idx_val, idx_test, total_epoch=100, patience=5, lr=0.001, reg_l2=0, weight_decay=0.0001):\n",
    "    model_name = save_dic['model']+str(save_dic['hid_feats'])+str(save_dic['out_feats'])+str(save_dic['reg_l2'])+save_dic[\"aggregator_type\"]\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
    "    best_cindex = 0\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.5, patience=patience, min_lr = 0.0001, verbose=True)\n",
    "    criterion = NegativeLogLikelihood(reg_l2)\n",
    "    features = g.ndata['h']\n",
    "#     e_feature = g.edata['w']\n",
    "    e_feature = None\n",
    "    labels = g.ndata['label']\n",
    "    events = g.ndata['event']\n",
    "    t_total = time.time()\n",
    "    with tqdm(range(total_epoch)) as t:\n",
    "        for epoch in t:\n",
    "            t.set_description('Epoch %d' % epoch)\n",
    "            start = time.time()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(g, features,e_feature)\n",
    "            # Compute loss\n",
    "            # Note that you should only compute the losses of the nodes in the training set.\n",
    "            loss_train = criterion(output[idx_train], labels[idx_train],events[idx_train], model).clone()\n",
    "            auc_train = c_index(-output[idx_train], labels[idx_train],events[idx_train])\n",
    "            \n",
    "            loss_train.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            val_output = model(g, features,e_feature)\n",
    "            loss_val = criterion(val_output[idx_val], labels[idx_val],events[idx_val], model).clone()\n",
    "            scheduler.step(loss_val)\n",
    "            \n",
    "            auc_val = c_index(-val_output[idx_val], labels[idx_val],events[idx_val])\n",
    "            auc_test = c_index(-val_output[idx_test], labels[idx_test],events[idx_test])\n",
    "\n",
    "            if auc_test>best_cindex:\n",
    "                best_cindex = auc_test.item()\n",
    "                print(\"Curent best :\", auc_test)\n",
    "                print(\"Its Val ACU:\",auc_val)\n",
    "                if epoch > 0 and best_cindex > 0.7 and auc_val > 0.65:\n",
    "                    torch.save(model.state_dict(), os.path.join(save_dic['save_path'], \n",
    "                                \"{}_ep{}_val{}_test{}.pth.gz\".format(model_name,epoch, np.around(auc_val,3),np.around(auc_test,3))))\n",
    "\n",
    "            t.set_postfix(\n",
    "                  {\"train_loss\":loss_train.item(), \"val_loss\":loss_val.item(),\n",
    "                  \"train_cindex\":auc_train.item(), \"val_auc\":auc_val.item(),\n",
    "                \"lr\":optimizer.param_groups[0]['lr']}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1100d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   6%| | 3/50 [00:00<00:04, 11.50it/s, train_loss=8.97e-5, val_loss=-2.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curent best : 0.6227927363807139\n",
      "Its Val ACU: 0.5309229305423406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  22%|▏| 11/50 [00:00<00:02, 15.66it/s, train_loss=0.000263, val_loss=-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20:  38%|▍| 19/50 [00:01<00:01, 16.27it/s, train_loss=0.000101, val_loss=3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    17: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26:  50%|▌| 25/50 [00:01<00:01, 16.55it/s, train_loss=-.000177, val_loss=-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    23: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32:  62%|▌| 31/50 [00:02<00:01, 16.81it/s, train_loss=-1.17e-5, val_loss=6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|█| 50/50 [00:03<00:00, 16.11it/s, train_loss=1.98e-5, val_loss=-2\n"
     ]
    }
   ],
   "source": [
    "save_dic = {\"model\":\"SAGE\", \n",
    "            \"hid_feats\":96, \n",
    "            'out_feats':16, \n",
    "            'reg_l2':0,\n",
    "            \"aggregator_type\":'mean',\n",
    "            \"save_path\":\"/home/jielian/lung-graph-project/Tumor_tranformer/logs/models/\"}\n",
    "sage96_norm = SAGE(g.ndata['h'].shape[1],hid_feats=save_dic[\"hid_feats\"],out_feats=save_dic['out_feats'], \n",
    "                   activation = F.softmax, aggregator_type=save_dic['aggregator_type'])\n",
    "train(g, sage96_norm, save_dic, idx_train,idx_val, idx_test, 50, patience=5, reg_l2=save_dic[\"reg_l2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269f9d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   6%| | 3/50 [00:00<00:04, 11.02it/s, train_loss=7.81, val_loss=1.92, t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curent best : 0.4791484032561052\n",
      "Its Val ACU: 0.3886094875628653\n",
      "Curent best : 0.6641202254226675\n",
      "Its Val ACU: 0.6248470844094061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  18%|▏| 9/50 [00:00<00:02, 15.29it/s, train_loss=0.721, val_loss=0.202"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31:  62%|▌| 31/50 [00:01<00:01, 16.33it/s, train_loss=0.21, val_loss=0.018"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curent best : 0.667501565435191\n",
      "Its Val ACU: 0.6629060758461329\n",
      "Curent best : 0.6687539135879774\n",
      "Its Val ACU: 0.6537991028952018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41:  82%|▊| 41/50 [00:02<00:00, 16.61it/s, train_loss=0.136, val_loss=0.02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    38: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|█| 50/50 [00:03<00:00, 16.12it/s, train_loss=0.0879, val_loss=0.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    50: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_dic = {\"model\":\"SAGE\", \n",
    "            \"hid_feats\":128, \n",
    "            'out_feats':16, \n",
    "            'reg_l2':0.00001,\n",
    "            \"aggregator_type\":'mean',\n",
    "            \"save_path\":\"/home/jielian/lung-graph-project/Tumor_tranformer/logs/models/\"}\n",
    "sage96_norm = SAGE(g.ndata['h'].shape[1],hid_feats=save_dic[\"hid_feats\"],out_feats=save_dic['out_feats'], \n",
    "                   activation = F.relu, aggregator_type=save_dic['aggregator_type'])\n",
    "train(g, sage96_norm, save_dic, idx_train,idx_val, idx_test, 50, patience=5, reg_l2=save_dic[\"reg_l2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cde77fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   2%| | 1/50 [00:00<00:06,  7.94it/s, train_loss=0.0135, val_loss=0.715"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curent best : 0.2954289292423294\n",
      "Its Val ACU: 0.336006524398532\n",
      "Curent best : 0.6882905447714465\n",
      "Its Val ACU: 0.6414299306782656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24:  46%|▍| 23/50 [00:01<00:01, 14.11it/s, train_loss=-.000265, val_loss=0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    21: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30:  58%|▌| 29/50 [00:02<00:01, 15.02it/s, train_loss=2.06e-5, val_loss=0."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    27: reducing learning rate of group 0 to 2.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35:  70%|▋| 35/50 [00:02<00:00, 15.40it/s, train_loss=4.87e-5, val_loss=0."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    33: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41:  82%|▊| 41/50 [00:03<00:00, 13.94it/s, train_loss=0.000144, val_loss=0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|█| 50/50 [00:03<00:00, 13.64it/s, train_loss=0.000344, val_loss=0\n"
     ]
    }
   ],
   "source": [
    "save_dic = {\"model\":\"GCN\", \n",
    "            \"hid_feats\":128, \n",
    "            'out_feats':12, \n",
    "            'reg_l2':0.00001,\n",
    "            \"aggregator_type\":'mean',\n",
    "            \"save_path\":\"/home/jielian/lung-graph-project/Tumor_tranformer/logs/models/\"}\n",
    "gcn_norm = GCN(g.ndata['h'].shape[1],hid_feats=save_dic[\"hid_feats\"],out_feats=save_dic['out_feats'], \n",
    "                   activation = F.relu)\n",
    "train(g, gcn_norm, save_dic, idx_train,idx_val, idx_test, 50, patience=5, reg_l2=save_dic[\"reg_l2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a208e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test!\n",
    "# save_dic = {\"model\":\"SAGE\", \n",
    "#             \"hid_feats\":96, \n",
    "#             'out_feats':32, \n",
    "#             \"aggregator_type\":'mean',\n",
    "#             \"save_path\":\"/home/jielian/lung-graph-project/Tumor_tranformer/logs/models/\"}\n",
    "# features = g.ndata['h']\n",
    "# e_feature = g.edata['w']\n",
    "# labels = g.ndata['label']\n",
    "# events = g.ndata['event']\n",
    "# # model = SAGE(g.ndata['h'].shape[1],hid_feats=96,out_feats=32, activation = F.relu, aggregator_type=\"mean\")\n",
    "# model = SAGE(g.ndata['h'].shape[1],hid_feats=save_dic[\"hid_feats\"],out_feats=save_dic['out_feats'], \n",
    "#                    activation = F.relu, aggregator_type=save_dic['aggregator_type'])\n",
    "# pre_train='SAGE96321e-05mean_ep3_val0.646_test0.775.pth.gz'\n",
    "# state_dict=torch.load(os.path.join(save_dic[\"save_path\"]+pre_train), map_location='cpu')\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.eval()\n",
    "# outputs = model.forward(g, features,e_feature)\n",
    "# auc_train = c_index(-outputs[idx_train], labels[idx_train],events[idx_train])\n",
    "# print(auc_train)\n",
    "# auc_val = c_index(-outputs[idx_val], labels[idx_val],events[idx_val])\n",
    "# print(auc_val)\n",
    "# auc_test = c_index(-outputs[idx_test], labels[idx_test],events[idx_test])\n",
    "# print(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test!\n",
    "save_dic = {\"model\":\"SAGE\", \n",
    "            \"hid_feats\":128, \n",
    "            'out_feats':32, \n",
    "            \"aggregator_type\":'mean',\n",
    "            \"save_path\":\"/home/jielian/lung-graph-project/Tumor_tranformer/logs/models/\"}\n",
    "features = g.ndata['h']\n",
    "e_feature = g.edata['w']\n",
    "labels = g.ndata['label']\n",
    "events = g.ndata['event']\n",
    "model = SAGE(g.ndata['h'].shape[1],hid_feats=save_dic[\"hid_feats\"],out_feats=save_dic['out_feats'], \n",
    "                   activation = F.relu, aggregator_type=save_dic['aggregator_type'])\n",
    "pre_train='SAGE128320.1mean_ep3_val0.761_test0.75.pth.gz'\n",
    "state_dict=torch.load(os.path.join(save_dic[\"save_path\"]+pre_train), map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "outputs = model.forward(g, features,e_feature)\n",
    "auc_train = c_index(-outputs[idx_train], labels[idx_train],events[idx_train])\n",
    "print(auc_train)\n",
    "auc_val = c_index(-outputs[idx_val], labels[idx_val],events[idx_val])\n",
    "print(auc_val)\n",
    "auc_test = c_index(-outputs[idx_test], labels[idx_test],events[idx_test])\n",
    "print(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91ea89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447926f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655eede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cceb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08edffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab19bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
